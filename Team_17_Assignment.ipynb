{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Math, Latex\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy_financial as npf\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Assignment\n",
    "### Team Number: 17\n",
    "### Team Member Names: John, Gen, Tim\n",
    "### Team Strategy Chosen: Risky "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements for this assignment:\n",
    "- Code needs to be dynamic\n",
    "- Must read in a csv file containing a finite number of stock tickers (with an example csv file in this repo)\n",
    "- Portfolio must contain only US listed stocks\n",
    "- Must have an average daily volume of at least 10 000 shares as calculated based on the time interval July 2, 2021 to October 22, 2021\n",
    "- Pick a minimum 10 maximum 20 stocks for portfolio.\n",
    "- If we choose n stocks, each stock must make up minimum (100/(2n))% of the portfolio when weighted by value as of closing prices on November 26, 2021\n",
    "- No individual stock may make up more than 35% of the portfolio when weighted by value\n",
    "- We have $100000 USD to spend on portfolio and all must be spent\n",
    "- When code is run with the .csv file, it must create a DataFrame \"FinalPortfolio\"\n",
    "    - With this portfolio, index starts at 1 and ends at the number of stocks that our code chooses.\n",
    "    - Headings must be: Ticker, Price, Shares, Value, Weight\n",
    "        - Ticker is the ticker selected\n",
    "        - Price is the price on November 26, 2021\n",
    "        - Shares is the number of shares purchased (can be fractional)\n",
    "        - Value is the total value of those shares\n",
    "        - Weighted is the weight that the value of shares represents relative to the value of the portfolio (which is $100,000)\n",
    "    - Needs to show that the total adds up to $100,000\n",
    "    - Also need to show the weights add to 100%\n",
    "    - This DataFrame must be printed to the screen as the second to last output to the screen.\n",
    "- After the DataFrame, one final DataFrame called \"Stocks\" which has the same index as \"Final Portfolio\" must be mad\n",
    "    - Only has the Tickers and Shares from \"Final Portfolio\"\n",
    "    - Must output this DataFrame to a csv file titled \"Stocks_Group_XX.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step #1: Filter out valid US tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_from_csv = pd.read_csv('Tickers.csv')\n",
    "stocks_from_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_lst = stocks_from_csv.iloc[:,0]\n",
    "stocks_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_from_csv.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_stock=yf.Ticker(stocks_lst[0])\n",
    "current_stock.info['market']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try doing the process below with threading\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "us_stock_lst = []\n",
    "stocks_lst\n",
    " \n",
    "def filter_valid(ticker_name):\n",
    "    try:\n",
    "        ticker_yf = yf.Ticker(ticker_name) # Store as variable to optimize access time\n",
    "\n",
    "        if (ticker_yf.info['regularMarketPrice'] != None) and (ticker_yf.info['market'] == 'us_market'):\n",
    "            us_stock_lst.append(ticker_yf)\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "       return e\n",
    " \n",
    "def runner():\n",
    "    threads= []\n",
    "    with ThreadPoolExecutor(max_workers=80) as executor:\n",
    "        for name in stocks_lst:\n",
    "            ticker = name\n",
    "            threads.append(executor.submit(filter_valid, ticker))\n",
    "\n",
    "runner()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_stock_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(us_stock_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Filter out tickers within date range based on daily average volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list to store the valid tickers\n",
    "valid_stock_list = []\n",
    "\n",
    "# time interval of July 02, 2021 to October 22, 2021\n",
    "start_date = \"2021-07-02\"\n",
    "end_date = \"2021-10-22\"\n",
    "\n",
    "# Finds the average daily volume of a stock\n",
    "def avg_daily_volume(ticker):\n",
    "    ticker_history = ticker.history(start=start_date,end=end_date,interval='1d')\n",
    "    ticker_vol_avg = ticker_history['Volume'].mean()\n",
    "    return ticker_vol_avg\n",
    "    \n",
    "    \n",
    "# iterates through us_stock_lst and checks if the stock has an average daily volume of at least 10,000 shares and appends to a list\n",
    "def volume_filter(ticker_lst):\n",
    "    for i in us_stock_lst:\n",
    "        if avg_daily_volume(i) >= 10_000:\n",
    "            valid_stock_list.append(i)\n",
    "        else:\n",
    "            continue\n",
    "    return valid_stock_list\n",
    "\n",
    "filtered_stocks = volume_filter(us_stock_lst)\n",
    "filtered_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_stocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step #3 Obtain the 20 most volatile stocks from the filtered lsit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_volatile (stock_count, ticker_lst, start_date, end_date): #Stock count will most likely be 20 #ticker_lst will always be filtered_stocks\n",
    "    #Get the stock history\n",
    "    stock_history = []\n",
    "    for y in range (len (ticker_lst)):\n",
    "        stock_history.append(ticker_lst[y].history(start=start_date, end=end_date))\n",
    "    \n",
    "    #Monthly Closing Prices dataframe\n",
    "    monthly_close = []\n",
    "    for g in range (len(stock_history)):\n",
    "        monthly_close.append(pd.DataFrame(stock_history[g]['Close']))\n",
    "    \n",
    "    #Combine the individual stocks together to make one large dataframe\n",
    "    share_prices = pd.concat (monthly_close, join='inner', axis=1)\n",
    "\n",
    "    # Rename the columns (will need to fix this soon)\n",
    "    share_prices.columns = ticker_lst\n",
    "\n",
    "    #Convert our dataframe into simply one column with standard deviation \n",
    "    sd_of_shares = share_prices.pct_change().std()\n",
    "\n",
    "    #Have to convert sd_of_shares into a dataframe\n",
    "    sd_df = pd.DataFrame(sd_of_shares)\n",
    "\n",
    "    #Find the 20 largest standard deviations meaning the most volatile\n",
    "    column = sd_df[0]\n",
    "    largest_names = []\n",
    "    for g in range (stock_count):\n",
    "        largest_names.append(column.idxmax().info['symbol'])\n",
    "        column = column.drop([column.idxmax()])\n",
    "\n",
    "    return largest_names\n",
    "\n",
    "largest_volatile = find_volatile(20, filtered_stocks, '2021-07-02', '2021-10-22')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_volatile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(largest_volatile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to get the ticker of a specific stock\n",
    "largest_volatile.index[5].info['symbol']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step #4: Find the porfolio with the best correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a global price dataframe to store all past data\n",
    "global_price_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add all data for tickers to a global price dataframe\n",
    "def update_price_df(ticker_lst, start_date, end_date):\n",
    "    # Load the global dataframe\n",
    "    global global_price_df\n",
    "    \n",
    "    # Read in the history closing price info\n",
    "    # Store in a dictionary where the key is the name of the ticker\n",
    "    hist_dic = {}\n",
    "    for i in ticker_lst:\n",
    "        if i not in global_price_df:\n",
    "            ticker_yf = yf.Ticker(i)\n",
    "            hist_dic[i] = ticker_yf.history(start=start_date, end=end_date)['Close']\n",
    "    \n",
    "    # Convert the dictionary to a dataframe\n",
    "    temp_price_df = pd.DataFrame(hist_dic)\n",
    "    \n",
    "    # If there is tickers to add, then resample it to month and add to the global closing price df\n",
    "    if not temp_price_df.empty:\n",
    "        # temp_prices_df = prices_df.resample('MS').first()\n",
    "        global_price_df = pd.concat([global_price_df, temp_price_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find all possible combinations of n tickers within the ticker_lst using a recursive function\n",
    "def combinations(arr, length, pre_arr=[]):\n",
    "    if len(pre_arr) == length:\n",
    "        return [pre_arr]\n",
    "    \n",
    "    combs = []\n",
    "    # Add each element to the previous array\n",
    "    for i, val in enumerate(arr):\n",
    "        cur_copy = pre_arr.copy()\n",
    "        cur_copy.append(val)\n",
    "        combs += combinations(arr[i+1:], length, cur_copy)\n",
    "    return combs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find the average correlation between each stock\n",
    "def find_avg_corr(ticker_lst, start_date, end_date):\n",
    "    # Load the global price dataframe\n",
    "    global global_price_df\n",
    "    \n",
    "    # Find the dataframe with the given tickers and filter the dates\n",
    "    price_df = global_price_df[ticker_lst]\n",
    "    price_df = price_df[(start_date <= price_df.index) & (price_df.index <= end_date)]\n",
    "    \n",
    "    # Find the correlation matrix\n",
    "    df_corr = price_df.corr()\n",
    "    \n",
    "    # Calculate the avg corr\n",
    "    sum_corr = 0\n",
    "    sum_count = 0\n",
    "    for i in range (len(ticker_lst)):\n",
    "        for j in range (i+1, len(ticker_lst)):\n",
    "            sum_corr += df_corr.loc[ticker_lst[i],ticker_lst[j]]\n",
    "            sum_count += 1\n",
    "    \n",
    "    # Calculate the return the avg correlation\n",
    "    return sum_corr/sum_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the combinaton of tickers with the maximum avg correlation\n",
    "def find_max_correlation(ticker_lst,  start_date, end_date, result_size = 10):\n",
    "    # Store the maximum value of corr and the portfolio\n",
    "    max_avg_corr = -1\n",
    "    max_corr_port = np.array([])\n",
    "    \n",
    "    # Load the global price dataframe\n",
    "    global global_price_df\n",
    "    \n",
    "    # Convert list to array and find the combinations\n",
    "    comb = combinations(np.array(ticker_lst), result_size)\n",
    "    \n",
    "    # Find the comb with the maximum average correlation\n",
    "    for i in comb:\n",
    "        avg_corr = find_avg_corr(i, start_date, end_date)\n",
    "        if avg_corr > max_avg_corr:\n",
    "            max_avg_corr = avg_corr\n",
    "            max_corr_port = i\n",
    "    \n",
    "    # Return the result sample\n",
    "    return max_corr_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Applying the functions\n",
    "# A random ticker list\n",
    "ticker_lst = ['MSFT', 'AAPL', 'GOOGL', 'AMZN', 'TSLA', 'FB', 'NVDA', 'NFLX', 'TSM', 'JPM',\n",
    "             'BABA', 'V', 'JNJ', 'UNH', 'WMT'] #, 'HD', 'BAC', 'MA', 'ASML', 'PG']\n",
    "\n",
    "# Update the global closing df\n",
    "update_price_df(ticker_lst, start_date, end_date)\n",
    "\n",
    "# Find the combination of tickers with maximum correlation\n",
    "max_corr_port = find_max_correlation(ticker_lst, start_date, end_date)\n",
    "\n",
    "# Display\n",
    "print('The portfolio with maximum avg correlation is:', max_corr_port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 Given a list of stocks, find the best distributions of the weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 Graph the portfolio standard deviation for different weightings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7 Given the chosen portfolio, measure its performance against the price weighted index consisting of all filtered US Stocks in Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8 Given the chosen portfolio of 10 stocks, graph the change in portfolio standard deviation as other risky stocks (from the 10 that werenâ€™t chosen in Step 4) are added in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For now, I do not have the stocks so I will use a sample list of stocks and its individual weighitngs\n",
    "# While I add stuff on, I will use the weighting and shares produced from John's function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graphing portion\n",
    "#graph out the standard deviation\n",
    "plt.figure(figsize=(20,15))\n",
    "\n",
    "plt.plot(['1 industry','2 industries', '3 industries', '4 industries', '5 industries', '6 industries', '7 industries', '8 industries', '9 industries', '10 industries'],SD, color='b', label='Standard Deviation')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Standard Deviation of the Percentage Return as more stocks are added')\n",
    "plt.xlabel('Number of Industries')\n",
    "plt.ylabel('Standard Deviation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9 Creating the final portfolio with csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contribution Declaration\n",
    "\n",
    "The following team members made a meaningful contribution to this assignment:\n",
    "\n",
    "Insert Names Here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
